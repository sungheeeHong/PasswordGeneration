{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embedding Model\n",
    "## 본 과정에서 불러오는 Embedding 모델을 만드는 과정을 담고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "추후 추가될 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일 불러오기\n",
    "import json\n",
    "with open(\"test-transcripts-aligned.json\") as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "# txt_dataset(list)에 json file의 utterance(내용 부분)만 꺼내서 담는다\n",
    "txt_dataset = []\n",
    "\n",
    "for i in data:\n",
    "    for j in data[i]:\n",
    "        txt_dataset.append(j['utterance'])\n",
    "\n",
    "# txt_dataset을 하나의 string data로 변환한다. \n",
    "txt_data = ''\n",
    "for txt in txt_dataset:\n",
    "    txt_data += txt\n",
    "# 예외처리\n",
    "txt_data = txt_data.replace('\\xa0', ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize, POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'll', 'pour', 'this', 'pestilence', 'into', 'his', 'ear', 'So', 'will']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RegexpTokenizer: 정규표현식(Regular expression)을 이용해 tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# \\w(alphabet, numbers) 패턴을 사용해 tokenize. 특수문자는 제외된다. \n",
    "tokenizer = RegexpTokenizer(\"[\\w]+\")\n",
    "tokens = tokenizer.tokenize(txt_data)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RP',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tag: tuple의 list 형태\n",
    "from nltk.tag import pos_tag\n",
    "pos_tokens = pos_tag(tokens)\n",
    "\n",
    "# dictionary로 변환\n",
    "pos_dict = {}\n",
    "for tag_tup in pos_tokens:\n",
    "    pos_dict.update({tag_tup[0]:tag_tup[1]})\n",
    "set(pos_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by POS tag, save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "VB_list = []\n",
    "JJ_list = []\n",
    "NN_list = []\n",
    "RT_list = []\n",
    "\n",
    "for key, value in pos_dict.items():\n",
    "    if \"VB\" in value:\n",
    "        VB_list.append(key)\n",
    "    elif \"JJ\" in value:\n",
    "        JJ_list.append(key)\n",
    "    elif \"NN\" in value:\n",
    "        NN_list.append(key)\n",
    "    else:\n",
    "        RT_list.append(key)\n",
    "    \n",
    "VB_list = np.array(VB_list)\n",
    "NN_list = np.array(NN_list)\n",
    "JJ_list = np.array(JJ_list)\n",
    "RT_list = np.array(RT_list)\n",
    "\n",
    "np.savez(\"pos_list\",\n",
    "            VB_list = VB_list,\n",
    "            JJ_list = JJ_list,\n",
    "            NN_list = NN_list,\n",
    "            RT_list = RT_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed word vector, save it\n",
    "품사별로 나눠서 embed하지 않고 한 번에 embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "vector_size = 128\n",
    "word_vector = FastText([list(pos_dict.keys())], vector_size = vector_size, window = 3, min_count = 1, workers = 1)\n",
    "word_vector.save(\"word_vector.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ptxt codebook, codebook embedding model, save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CodebookModule import Codebook_HorizontalSliding\n",
    "PW_rule = Codebook_HorizontalSliding\n",
    "dic_codebook = {}\n",
    "\n",
    "for pos_name, pos_list in {'NN_list': NN_list, 'VB_list':VB_list, 'JJ_list':JJ_list, 'RT_list':RT_list}.items():\n",
    "    dict_pos = PW_rule(pos_list)\n",
    "    encoded_pos = [list(dict_pos.keys())]\n",
    "    encoded_pos_vec = FastText(encoded_pos, vector_size = vector_size, window = 3, min_count = 1, workers = 1)\n",
    "    try:\n",
    "        if pos_name == 'NN_list':\n",
    "            encoded_pos_vec.save(\"NN_pwd.model\")\n",
    "        elif pos_name == 'VB_list':\n",
    "            encoded_pos_vec.save(\"VB_pwd.model\")\n",
    "        elif pos_name == 'JJ_list':\n",
    "            encoded_pos_vec.save(\"JJ_pwd.model\")\n",
    "        else:\n",
    "            encoded_pos_vec.save(\"RT_pwd.model\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No such list or model: {pos_list}\")\n",
    "\n",
    "    pos_codebook = []\n",
    "    for pwd in encoded_pos_vec.wv.index_to_key:\n",
    "        temp = np.hstack((word_vector.wv[dict_pos[pwd]], encoded_pos_vec.wv[pwd]))\n",
    "        pos_codebook.append(temp)\n",
    "    dic_codebook.update({pos_name:pos_codebook})\n",
    "\n",
    "NN_codebook = dic_codebook['NN_list']\n",
    "VB_codebook = dic_codebook['VB_list']\n",
    "JJ_codebook = dic_codebook['JJ_list']\n",
    "RT_codebook = dic_codebook['RT_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"pos_codebook\",\n",
    "            VB_codebook = VB_codebook,\n",
    "            JJ_codebook = JJ_codebook,\n",
    "            NN_codebook = NN_codebook,\n",
    "            RT_codebook = RT_codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
